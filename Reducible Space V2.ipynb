{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa242cb-391a-4773-ad00-845ab8c42008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: This cell imports the necessary packages\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b22d56-394d-49dc-a752-888ab9a8d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Enter the 4 file paths and 1 directory (folder) path in the sections including: _file_path = \"_insert_here_\"\n",
    "\n",
    "# Read the instructions above each to ensure the file has the right columns / data\n",
    "\n",
    "\"\"\"\n",
    "Import 1: Campus Properties CSV\n",
    "> This table contains enrolment information for each school campus, as well as properties that are used as inclusion/exclusion criteria.\n",
    "> Each row represents data for a different campus (according to CampusId)\n",
    "> The table MUST include the columns: \"CampusId\", \"primary_enrolments\", \"secondary_enrolments\"\n",
    "\"\"\"\n",
    "campus_properties_file_path = \"_insert_here_\"\n",
    "campus_properties_data_types = {'CampusId' : str, 'School Type' : str,'primary_enrolments' : int, 'secondary_enrolments' : int }\n",
    "campus_properties_columns = [\"CampusId\", \"primary_enrolments\", \"secondary_enrolments\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Import 2: Building Properties CSV\n",
    "> This table contains the BuildingId, condition & functionality for each building in the portfolio, as well as any properties that are used as inclusion/exclusion criteria.\n",
    "> Each row represents data for a different building (according to BuildingId)\n",
    "> The table MUST include the columns: \"CampusId\", \"BuildingId\", \"Functionality\", \"Condition\"\n",
    "\"\"\"\n",
    "building_properties_file_path = \"_insert_here_\"\n",
    "building_properties_data_types = { 'CampusId' : str, 'BuildingId' : str, 'Condition' : float , 'Functionality' : float }\n",
    "building_properties_columns = [\"BuildingId\", \"CampusId\", \"Condition\", \"Functionality\"]\n",
    "\n",
    "\"\"\"\n",
    "Import 3:  Inclusion Exclusion Register CSV\n",
    "> This table specifies the criteria that are used to determine whether a given building or campus are included in the reducible space calculation.\n",
    "> Each row represents a different exclusion criteria, which can be activated or deactivated using the column \"exlcude_true_false\"\n",
    "> The table MUST include the columns:\n",
    "\"table_name\": this value must be either 'Campus Properties' or 'Building Properties'. It is used to specify which table the exclusion is being applied to.\n",
    "\"column_name\": this is the column within the specified table that the exlcusion is being applied to\n",
    "\"exclude_true_false\": this indicates whether the exclusion is active or not; TRUE = active\n",
    "\"exclusion_type\": this indicates whether the exclusion is applied using the 'num_range' columns, or the 'string_value_criteria' column. The two options for this column are 'num_range', or 'string_value'\n",
    "\"num_range_start\": indicates where the exclusion range begins. I.e. down to and including the number that is specified\n",
    "\"num_range_stop\": indicates where the exclusion range ends. I.e. up to and including the number that is specified\n",
    "\"string_value_criteria\": indicates one or more string values which are then treated as exclusion criteria within the given column. Multiple values should be separated by comma's.\n",
    "\"\"\"\n",
    "inclusion_exclusion_file_path = \"_insert_here_\"\n",
    "inclusion_exclusion_data_types = { 'filter_true_false' : bool, 'exclusion_type' : str, 'num_range_start' : float, 'num_range_stop' : float }\n",
    "inclusion_exclusion_columns = [\"table_name\", \"column_name\",\n",
    "                                \"exclude_true_false\", \"exclusion_type\",\n",
    "                                \"num_range_start\", \"num_range_stop\", \"string_value_criteria\"]\n",
    "\n",
    "\"\"\"\n",
    "Import 4:  AIMS extract CSV\n",
    "> This is an extract from AIMS that is commonly known as the 'building and room report'. It provides the data for calculating existing space at the FAS 1 - 2 level for each building.\n",
    "> It can be found at this address: https://partner.eduweb.vic.gov.au/collaboration/AIMS/S1R1%20CORP/Forms/DET%20Document%20Set/docsethomepage.aspx?RootFolder=%2Fcollaboration%2FAIMS%2FS1R1%20CORP%2FS1%20R1%20AIMS%20REPORT%20EXAMPLES%2FRPT001%20-%20Extract&FolderCTID=0x0120007D803ED7D3E25A4587B6EED2CA7F9FB5&View=%7B8E2F392E-4991-44AF-9300-0D91D42638C7%7D\n",
    "\"\"\"\n",
    "AIMS_extract_file_path = \"_insert_here_\"\n",
    "AIMS_report_data_types = { 'FloorArea' : float, 'CampusId' : str, 'BuildingId' : str, 'SpaceEntClass18' : str }\n",
    "AIMS_report_columns = [\"SpaceEntClass18\", \"CampusId\", \"FloorArea\", \"BuildingId\"]\n",
    "\n",
    "\"\"\"\n",
    "Import 5:  FAS file folder\n",
    "> This is a folder that contains 4 files which each provide different sections of the 2018 Facility Area Schedule. They are:\n",
    "1. \"FAS 1 Categories\"\n",
    "2. \"FAS 2 Categories\"\n",
    "3. \"Primary FAS\"\n",
    "4. \"Secondary FAS\"\n",
    "\n",
    "Note: These MUST retain the same structure in order for the model to work, although if required, additional enrolment bands can be added without causing errors. The names for each must also stay consistent.\n",
    "\"\"\"\n",
    "\n",
    "FAS_folder_path = \"_insert_here_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4fe01-6962-4ae9-8062-2a2b3343e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: These functions are used to check whether the file contains the right columns and data types\n",
    "\n",
    "def check_csv_columns(df, expected_columns):\n",
    "    columns = df.columns.tolist()\n",
    "    \n",
    "    naughty_list = []\n",
    "    \n",
    "    for i in expected_columns:\n",
    "        if i in columns:\n",
    "            continue\n",
    "        else:\n",
    "            naughty_list.append(i)\n",
    "    \n",
    "    if len(naughty_list) > 0:\n",
    "        raise ValueError(f\"The following columns were expected but not found: {naughty_list}. Try checking for spelling/grammar differences or add the required columns.\")\n",
    "\n",
    "def convert_columns(df, column_types):\n",
    "    for column, dtype in column_types.items():\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].astype(dtype)\n",
    "        else:\n",
    "            df[column] = pd.Series(dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc33a8d-52da-48d2-95e8-34992853d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: This function iterates through the file names specified in the file_names list, attaching them to the folder path and retrieving the CSV file with the given name\n",
    "# It then processes the CSV files into the format that is used in the model, and assigns them to a dictionary\n",
    "\n",
    "def upload_fas(fas_folder_path):\n",
    "    file_names = ['FAS 1 Categories.csv', 'FAS 2 Categories.csv', 'Primary FAS.csv', 'Secondary FAS.csv']\n",
    "    FAS_dataframes = { }\n",
    "\n",
    "    for file in os.listdir(fas_folder_path):\n",
    "        for idx, target_file in enumerate(file_names):\n",
    "            if file == target_file:\n",
    "                file_path = os.path.join(fas_folder_path, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                FAS_dataframes[target_file] = df                 \n",
    "                break\n",
    "\n",
    "    \"\"\"Below is the method for processing the FAS1-2 Category dataframes\"\"\"\n",
    "        \n",
    "    FAS_1_categories = FAS_dataframes['FAS 1 Categories.csv']\n",
    "    FAS_2_categories = FAS_dataframes['FAS 2 Categories.csv']\n",
    "    FAS_1_categories = FAS_1_categories.set_index(\"Facility Area Schedule\")\n",
    "    FAS_2_categories = FAS_2_categories.set_index(\"Facility Area Schedule\")\n",
    "\n",
    "    FAS_1_categories = FAS_1_categories\n",
    "    FAS_2_categories = FAS_2_categories\n",
    "\n",
    "\n",
    "    \"\"\"Below is the method for processing the Pri_FAS & Sec_FAS dataframes\"\"\"\n",
    "\n",
    "    Pri_FAS = FAS_dataframes['Primary FAS.csv']\n",
    "    Sec_FAS = FAS_dataframes['Secondary FAS.csv']\n",
    "\n",
    "    # 2: rename columns to match later requirements\n",
    "    Sec_FAS.rename(columns = {'Upper Enrolments': 'FAS Layer 2', 'FAS Level' : 'FAS Layer'}, inplace = True)\n",
    "    Pri_FAS.rename(columns = {'Upper Enrolments': 'FAS Layer 2'}, inplace = True)\n",
    "\n",
    "    # 3: Set the category names as the indices\n",
    "    Sec_FAS_index = Sec_FAS['FAS Layer 2']\n",
    "    Sec_FAS = Sec_FAS.set_index(Sec_FAS_index)\n",
    "    Pri_FAS_index = Pri_FAS['FAS Layer 2']\n",
    "    Pri_FAS = Pri_FAS.set_index(Pri_FAS_index)\n",
    "\n",
    "    # 4: remove FAS categories column\n",
    "    Sec_FAS = Sec_FAS.drop(['FAS Layer 2'], axis = 1)\n",
    "    Pri_FAS = Pri_FAS.drop(['FAS Layer 2'], axis = 1)\n",
    "\n",
    "    # 5: insert an enrolment band for '0' students\n",
    "    Pri_FAS.insert(1, '0', 0)\n",
    "    Sec_FAS.insert(1, '0', 0)\n",
    "\n",
    "    # 6: insert a column classifying which enrolment type the row belongs to\n",
    "\n",
    "    Pri_FAS.insert(1, 'Student Type', 'Primary')\n",
    "\n",
    "    Sec_FAS.insert(1, 'Student Type', 'Secondary')\n",
    "\n",
    "    # 7: Splits the indices into a multi-index depending on FAS Layer\n",
    "\n",
    "    def split_index(FAS_df):\n",
    "        FAS_1 = None\n",
    "        new_index = []\n",
    "\n",
    "        for n, index in enumerate(FAS_df.index):\n",
    "            layer = FAS_df.iat[n, 0]\n",
    "\n",
    "            if layer == 1:\n",
    "                FAS_1 = index\n",
    "            elif layer == 2:\n",
    "                new_index.append((FAS_1, index))\n",
    "\n",
    "        FAS_df = FAS_df[FAS_df['FAS Layer'] > 1]\n",
    "        FAS_df.set_index(pd.MultiIndex.from_tuples(new_index, names=['FAS 1', 'FAS 2']), inplace=True)\n",
    "        FAS_df = FAS_df.drop(columns=[\"FAS Layer\"])\n",
    "\n",
    "        return FAS_df\n",
    "\n",
    "    Pri_FAS = split_index(Pri_FAS)\n",
    "\n",
    "    Sec_FAS = split_index(Sec_FAS)\n",
    "\n",
    "    # 8: Assigns the Core/Support label to each row (FAS Category)\n",
    "\n",
    "    def core_support(FAS_df, FAS_2_categories):\n",
    "        \n",
    "        \n",
    "        # Retrieves the FAS_1 values from the first layer of index from the multi-index dataframe; get_level_values retrieves values from a multi-index\n",
    "        FAS_1_values = FAS_df.index.get_level_values(0).unique() \n",
    "        FAS_2_values = FAS_df.index.get_level_values(1)\n",
    "        \n",
    "        # This creates a list of core/support values based on the FAS_2 values in the FAS_df dataframe\n",
    "        core_support_column = []\n",
    "        for FAS_2 in FAS_2_values:\n",
    "            if FAS_2_categories.at[FAS_2, \"Space classification\"] == 'Core':\n",
    "                core_support_column.append('Core')\n",
    "            elif FAS_2_categories.at[FAS_2, \"Space classification\"] == 'Support':\n",
    "                core_support_column.append('Support')   \n",
    "            else:\n",
    "                core_support_column.append('N/A')\n",
    "                \n",
    "        # This inserts the list core/support classication as the first column within the dataframe\n",
    "        FAS_df.insert(0, \"Space classification\", core_support_column)\n",
    "        \n",
    "        return FAS_df\n",
    "\n",
    "    Pri_FAS = core_support(Pri_FAS, FAS_2_categories) # <-- Uses above function to add core/support values within the FAS dataframes\n",
    "    Sec_FAS = core_support(Sec_FAS, FAS_2_categories)\n",
    "\n",
    "    FAS_dataframes_dict = { 'Pri_FAS' : Pri_FAS, 'Sec_FAS' : Sec_FAS, 'FAS_1_categories' : FAS_1_categories, 'FAS_2_categories' : FAS_2_categories }\n",
    "\n",
    "    return FAS_dataframes_dict\n",
    "\n",
    "# The following code retrieves the four FAS files, and then defines them using the FAS_dataframes_dict output from the upload_FAS function \n",
    "FAS_dictionary = upload_fas(FAS_folder_path) \n",
    "\n",
    "Pri_FAS = FAS_dictionary['Pri_FAS']\n",
    "Sec_FAS = FAS_dictionary['Sec_FAS']\n",
    "FAS_1_categories = FAS_dictionary['FAS_1_categories']\n",
    "FAS_2_categories = FAS_dictionary['FAS_2_categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417c90d-c6b1-4c78-9356-b6a789455b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5: This is the generic CSV-reading function for the other files\n",
    "\n",
    "def upload_csv(file_path, dtypes, columns):\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)   #  <-- This converts the csv file into a pandas dataframe (table)\n",
    "        check_csv_columns(df, columns)   #  <-- This is the function that tests whether all the required columns are included in the dataframe\n",
    "    except:\n",
    "        print(f\"Failed to read file: {file_path}\")\n",
    "        \n",
    "    convert_columns(df, dtypes)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5abac-04c3-4bb6-96d1-5e823bc91195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6: This converts three csv files from cell #2 into pandas dataframes\n",
    "\n",
    "inclusion_exclusion_df = upload_csv(inclusion_exclusion_file_path, inclusion_exclusion_data_types, inclusion_exclusion_columns)\n",
    "\n",
    "campus_properties_df = upload_csv(campus_properties_file_path, campus_properties_data_types, campus_properties_columns)\n",
    "\n",
    "building_properties_df = upload_csv(building_properties_file_path, building_properties_data_types, building_properties_columns)\n",
    "\n",
    "# Write the dataframe below to view it. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b6ba6-2fa5-43c1-b7b5-3ef3b25568e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7: This uploads and cleans the Building & Room Report\n",
    "\n",
    "def upload_aims_report(file_path, dtypes, columns):\n",
    "    \n",
    "    aims_report_df = pd.read_csv(file_path)\n",
    "    \n",
    "    check_csv_columns(aims_report_df, columns)\n",
    "    \n",
    "    # This converts the columns to the right data type\n",
    "    convert_columns(aims_report_df, dtypes)\n",
    "    \n",
    "    \n",
    "    # This creates a dataframe with the columns specified in the list\n",
    "    actual_space_extract = aims_report_df.loc[:,['CampusId', 'SchoolNo', 'CampusName', 'BuildingId', 'BuildingName', 'SpaceId','SpaceEntClass18', 'FloorArea', 'Classification']]\n",
    "\n",
    "    # This produces a dataframe with all the unique SpaceEntClass18 values broken into the constituent values e.g. so that they can be matched to FAS 1 & 2 categories\n",
    "    space_classifications = aims_report_df['SpaceEntClass18'].unique()\n",
    "    classification_index = pd.DataFrame(space_classifications, columns=['space_classifications']).set_index('space_classifications')\n",
    "    classification_index[['year', 'standard', 'FAS 1', 'FAS 2', 'FAS 3']] = classification_index.index.to_series().str.split('\\\\\\\\', expand=True)     \n",
    "\n",
    "\n",
    "    # filtering out any rows with null / not numerical values for floor area\n",
    "    actual_space_extract = actual_space_extract.loc[(actual_space_extract[\"FloorArea\"] > -1)]\n",
    "\n",
    "    # this assigns two new columns to the actual_space_extract file\n",
    "    actual_space_extract = actual_space_extract.assign(**{\"FAS 1\": \"\", \"FAS 2\": \"\"})\n",
    "\n",
    "    # Uses 'map' to retrieve the FAS 1 & 2 categories from the classification index according to the SpaceEntClass18 value in the AIMS extract\n",
    "    actual_space_extract['FAS 1'] = actual_space_extract['SpaceEntClass18'].map(classification_index['FAS 1'])\n",
    "    actual_space_extract['FAS 2'] = actual_space_extract['SpaceEntClass18'].map(classification_index['FAS 2'])\n",
    "\n",
    "    # Uses `str.strip()` to remove leading and trailing spaces from the columns\n",
    "    actual_space_extract['FAS 1'] = actual_space_extract['FAS 1'].str.strip()\n",
    "    actual_space_extract['FAS 2'] = actual_space_extract['FAS 2'].str.strip()\n",
    "\n",
    "    aims_report_df = actual_space_extract\n",
    "\n",
    "    core_space_categories = Pri_FAS[Pri_FAS['Space classification'] == 'Core'].index.get_level_values(1).tolist() + Sec_FAS[Sec_FAS['Space classification'] == 'Core'].index.get_level_values(1).tolist()\n",
    "\n",
    "    FAS_2_space = aims_report_df.pivot_table(index = 'BuildingId', columns = 'FAS 2',\n",
    "                                                      values='FloorArea',  aggfunc = 'sum',  fill_value = 0) # <-- This creates a dataframe with the \n",
    "\n",
    "    FAS_1_space = aims_report_df.pivot_table(index = 'BuildingId', columns = 'FAS 1',\n",
    "                                                      values='FloorArea',  aggfunc = 'sum',  fill_value = 0)\n",
    "\n",
    "    FAS_2_core_space = FAS_2_space.filter(items = core_space_categories)\n",
    "    \n",
    "    return aims_report_df, core_space_categories, FAS_2_space, FAS_1_space, FAS_2_core_space\n",
    "\n",
    "aims_report_outputs = upload_aims_report(AIMS_extract_file_path, AIMS_report_data_types, AIMS_report_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a10a6f-65df-4d4e-9c25-2e3d8b340f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 This assigns variables to each of the outputs from the upload_aims_report function\n",
    "\n",
    "\n",
    "# 8.1: This is a dataframe extracted from the BRR: each row is for an individual room/space, and columns contain information about floor area, building I, campus Id, and FAS classifications.\n",
    "# Columns: 'CampusId', 'SchoolNo', 'CampusName', 'BuildingId', 'BuildingName', 'SpaceId', 'SpaceEntClass18', 'FloorArea', 'Classification', 'FAS 1',  'FAS 2'],\n",
    "aims_report_df = aims_report_outputs[0]\n",
    "\n",
    "# 8.2: This is a list of the FAS 2 categories that are considered çore\n",
    "core_space_categories = aims_report_outputs[1]\n",
    "\n",
    "# 8.3 This is a dataframe where each row is for a given building (index = BuildingId), and the columns indicate the amount of aggregated floor area within each FAS 2 space type\n",
    "FAS_2_space = aims_report_outputs[2]\n",
    "\n",
    "# 8.4: This is a dataframe where each row is for a given building (index = BuildingId), and the columns indicate the amount of aggregated floor area within each FAS 1 space type\n",
    "FAS_1_space = aims_report_outputs[3]\n",
    "\n",
    "# 8.5: This is a dataframe where each row is for a given building (index = BuildingId), and the columns indicate the amount of aggregated core space within each FAS 2 space type\n",
    "# I.e. same as FAS_2_space dataframe, except filtered to exlcude non-core space categories from the columns\n",
    "FAS_2_core_space = aims_report_outputs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f682a86a-913f-4bc8-83f0-e2a252468cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Type</th>\n",
       "      <th>Index</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.combination_FAS_1_core_space,</td>\n",
       "      <td>pd.Series</td>\n",
       "      <td>FAS 1 categories</td>\n",
       "      <td>Sum of floor area from each building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FAS_1_remaining_excess_space</td>\n",
       "      <td>pd.Series</td>\n",
       "      <td>FAS 1 categories</td>\n",
       "      <td>Campus excess core space, minus combination co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FAS_1_remaining_core_space</td>\n",
       "      <td>pd.Series</td>\n",
       "      <td>FAS 1 categories</td>\n",
       "      <td>Campus core space, minus combination core space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remaining_total_space</td>\n",
       "      <td>float value</td>\n",
       "      <td>NA</td>\n",
       "      <td>Total sum of remaining core space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>percentage_excess_core_space</td>\n",
       "      <td>float value</td>\n",
       "      <td>NA</td>\n",
       "      <td>Excess core space percentage after combination...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reducible_classification</td>\n",
       "      <td>Boolean</td>\n",
       "      <td>NA</td>\n",
       "      <td>True = combination is reduxible, False = excluded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reducible_space</td>\n",
       "      <td>float value</td>\n",
       "      <td>NA</td>\n",
       "      <td>Sum of floor area for the combination</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Attribute         Type             Index  \\\n",
       "0  .combination_FAS_1_core_space,    pd.Series  FAS 1 categories   \n",
       "1    FAS_1_remaining_excess_space    pd.Series  FAS 1 categories   \n",
       "2      FAS_1_remaining_core_space    pd.Series  FAS 1 categories   \n",
       "3           remaining_total_space  float value                NA   \n",
       "4    percentage_excess_core_space  float value                NA   \n",
       "5        reducible_classification      Boolean                NA   \n",
       "6                 reducible_space  float value                NA   \n",
       "\n",
       "                                                Data  \n",
       "0               Sum of floor area from each building  \n",
       "1  Campus excess core space, minus combination co...  \n",
       "2    Campus core space, minus combination core space  \n",
       "3                  Total sum of remaining core space  \n",
       "4  Excess core space percentage after combination...  \n",
       "5  True = combination is reduxible, False = excluded  \n",
       "6              Sum of floor area for the combination  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9: This class defines a new object which is used to calculate & store information about each combination of buildings within each campus. See bottom of cell for attributes:\n",
    "\n",
    "class Combination():\n",
    "    def __init__(self, combination_tuple, FAS_1_excess_core_space, building_dictionary, FAS_1_core_entitlement, FAS_1_core_space, entitled_core_space):\n",
    "\n",
    "       \n",
    "        # converts negative values in the excess space FAS 1 table to zero:\n",
    "        # This is so that we can detect whether the reduction of this combination would affect FAS 1 categories which are already under-entitled\n",
    "        \n",
    "        FAS_1_excess_core_space = FAS_1_excess_core_space.apply(lambda x: x if x >= 0 else 0) # <-- this applies a function which converts negative values to zero. Output: pd.Series\n",
    "\n",
    "        combination_space = FAS_1_core_entitlement\n",
    "\n",
    "        combination_space = combination_space.apply(lambda x: 0) # <-- creates a fresh pd.Series with all the FAS 1 categories and 0 for actual space\n",
    "\n",
    "        # This loop finds the amount of space in each FAS 1 category\n",
    "        for ID in combination_tuple:\n",
    "\n",
    "            # retrieves the building object from the building dictionary created for the current campus object\n",
    "            building = building_dictionary[ID]\n",
    "            \n",
    "            building_space = building.FAS_1_core_space[\"Actual Space\"]\n",
    "\n",
    "            # adds the building space to the pd.series representing the combination's space\n",
    "            combination_space = combination_space.add(building_space, fill_value = 0)\n",
    "            \n",
    "        # This is the \"actual space\" for the combination of buildings\n",
    "        self.combination_FAS_1_core_space = combination_space\n",
    "\n",
    "        self.FAS_1_remaining_excess_space = FAS_1_excess_core_space.sub(combination_space, fill_value = 0) # <--  subtracts the combination area from the excess core space to find the remaining excess space at each FAS 1 level\n",
    "        \n",
    "        self.FAS_1_remaining_core_space = FAS_1_core_space.sub(combination_space, fill_value = 0) #  <-- This subtracts the combination area from the core space to find the remaining space at each FAS 1 level\n",
    "\n",
    "        self.remaining_total_space = self.FAS_1_remaining_core_space.sum() #  <-- This is a float value that shows the sum of core space\n",
    "        \n",
    "        \n",
    "        # This finds the percentage of excess space remaining after the combination is removed\n",
    "        actual = self.remaining_total_space\n",
    "        entitled = entitled_core_space\n",
    "        self.percentage_excess_core_space = ((actual - entitled) / actual ) * 100\n",
    "        \n",
    "        \"\"\" This section classifies the combination as reducible or not reducible:\n",
    "        Note: the conditions under which a combination is excluded are:\n",
    "        A) It reduces the overall percentage of excess core space for the campus below 0%\n",
    "        B) It reduces the core space of an over-entitled category below zero\n",
    "        C) It reduces the space of a category that is already under-entitled\n",
    "        \"\"\"\n",
    "        reducible_classification = True\n",
    "        \n",
    "        for i in self.FAS_1_remaining_excess_space:\n",
    "            if i < 0:\n",
    "                reducible_classification = False\n",
    "        \n",
    "        if self.percentage_excess_core_space < 0:\n",
    "            reducible_classification = False\n",
    "            \n",
    "        self.reducible_classification = reducible_classification\n",
    "\n",
    "        self.reducible_space = self.combination_FAS_1_core_space.sum()\n",
    "\n",
    "        \n",
    "# Attributes: combination attributes can be called by using: campus_variable.combinations[ (combination tuple) ].____attribute____\n",
    "attribute_list = [\".combination_FAS_1_core_space,\", \"FAS_1_remaining_excess_space\",\n",
    "                  \"FAS_1_remaining_core_space\", \"remaining_total_space\", \"percentage_excess_core_space\", \"reducible_classification\", \"reducible_space\"]               \n",
    "type_list = [\"pd.Series\", \"pd.Series\", \"pd.Series\", \"float value\", \"float value\", \"Boolean\", \"float value\"]\n",
    "index_list = [ \"FAS 1 categories\", \"FAS 1 categories\", \"FAS 1 categories\", \"NA\", \"NA\", \"NA\", \"NA\"]\n",
    "data_list = [\"Sum of floor area from each building\" , \"Campus excess core space, minus combination core space\",\n",
    "             \"Campus core space, minus combination core space\", \"Total sum of remaining core space\", \"Excess core space percentage after combination space is subtracted\",\n",
    "             \"True = combination is reduxible, False = excluded\" , \"Sum of floor area for the combination\"]\n",
    "combination_attributes_dictionary = { \"Attribute\" : attribute_list, \"Type\" : type_list, \"Index\" : index_list, \"Data\" : data_list }\n",
    "combination_attributes = pd.DataFrame(combination_attributes_dictionary)\n",
    "\n",
    "combination_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50229a9d-30a1-464b-b47e-2ed76c6867c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 10: This cell defines the building and campus classes:\n",
    "\n",
    "\n",
    "# The campus class performs most of the calculations, and has sections which use the building/combination classes to calculate reducible space\n",
    "class Campus():\n",
    "    def __init__(self, campus_id, campus_properties, aims_extract, FAS_2_space, FAS_2_core_space, building_properties, inclusion_exclusion_df):\n",
    "        \n",
    "        self.enrolment_categories_tuple = self.enrolmentment_categories(campus_id, campus_properties, FAS_1_categories, FAS_2_categories, Sec_FAS, Pri_FAS) # # # !!! The FAS category data will need to have the PageOne class specified        \n",
    "        \n",
    "        buildings = building_properties[building_properties['CampusId'] == campus_id]\n",
    "        \n",
    "        self.buildings = buildings['BuildingId'].unique()\n",
    "        \n",
    "        self.Pri_entitled = self.FAS_1_2_entitlement_calc(Pri_FAS, Sec_FAS, self.enrolment_categories_tuple)[0] # !!! The FAS category data will need to have the PageOne class specified\n",
    "        \n",
    "        self.Sec_entitled = self.FAS_1_2_entitlement_calc(Pri_FAS, Sec_FAS, self.enrolment_categories_tuple)[1] # !!! The FAS category data will need to have the PageOne class specified\n",
    "        \n",
    "        self.FAS_2_entitlement = self.FAS_2_entitlement_calc(self.Pri_entitled, self.Sec_entitled, FAS_2_categories)[0]\n",
    "        \n",
    "        self.FAS_2_core_entitlement = self.FAS_2_entitlement_calc(self.Pri_entitled, self.Sec_entitled, FAS_2_categories)[1]\n",
    "        \n",
    "        self.FAS_1_core_entitlement = self.FAS_1_core_entitlement # <-- This is a pd.Series that shows the entitlement at the FAS 1 level\n",
    "        \n",
    "        self.FAS_1_entitlement = self.FAS_1_entitlement # <-- Same as above, except with non-core FS 2 categories filtered out\n",
    "        \n",
    "        self.entitled_core_space = self.FAS_1_core_entitlement.sum() # <-- This finds the sum of entitled core space i.e  ENTITLED CORE SPACE FOR THE CAMPUS\n",
    "        \n",
    "        self.buildings_dictionary = {}\n",
    "        \n",
    "        for ID in self.buildings:\n",
    "            self.buildings_dictionary[ID] = Building(ID, building_properties, FAS_2_space, FAS_2_core_space, aims_extract)\n",
    "              \n",
    "        \"\"\"\n",
    "        Building attributes:\n",
    "        1. self.FAS_2_space\n",
    "        2. self.FAS_1_space\n",
    "        3. self.FAS_1_core_space\n",
    "        4. self.FAS_1_2_core_space\n",
    "        \n",
    "        The below section calculates the total & core space for the campus:\n",
    "        \"\"\"\n",
    "        \n",
    "        FAS_1_space_table_list = []\n",
    "        FAS_1_core_space_table_list = []\n",
    "        \n",
    "        for i in self.buildings:\n",
    "            FAS_1_space_table = self.buildings_dictionary[i].FAS_1_space\n",
    "            FAS_1_space_table_list.append(FAS_1_space_table)\n",
    "            \n",
    "            FAS_1_core_space_table = self.buildings_dictionary[i].FAS_1_core_space\n",
    "            FAS_1_core_space_table_list.append(FAS_1_core_space_table)\n",
    "            \n",
    "        self.FAS1_merged = pd.concat(FAS_1_space_table_list, axis = 0)\n",
    "        self.FAS_1_space = self.FAS1_merged.sum()\n",
    "        self.total_space = self.FAS_1_space.sum()\n",
    "\n",
    "        self.FAS1_core_merged = pd.concat(FAS_1_core_space_table_list, axis = 1, join = 'outer')\n",
    "        self.FAS1_core_merged.fillna(0, inplace=True)\n",
    "        \n",
    "        # This is a pd.Series that shows the core space for each FAS 1 category\n",
    "        self.FAS_1_core_space = self.FAS1_core_merged.sum(axis = 1)\n",
    "        \n",
    "        # This is a float value that shows the sum of core space\n",
    "        self.total_core_space = self.FAS_1_core_space.sum()  #  <-- TOTAL CORE SPACE FOR CAMPUS\n",
    "        \n",
    "        \"\"\"\n",
    "        The below section calculates the excess core space for the campus:\n",
    "        \"\"\"\n",
    "        \n",
    "        actual = self.total_core_space\n",
    "        entitled = self.entitled_core_space\n",
    "\n",
    "        self.percentage_excess_core_space = ((actual - entitled) / actual ) * 100\n",
    "\n",
    "        # This provides the excess floor area at each FAS 1 level\n",
    "        self.FAS_1_excess_core_space = self.FAS_1_core_space.sub(self.FAS_1_core_entitlement, fill_value = 0)\n",
    "        \n",
    "        \"\"\"\n",
    "        The below section calculates the combinations of reducible buildings:\n",
    "        \"\"\"\n",
    "        \n",
    "        building_exclusions = inclusion_exclusion_df.loc[(inclusion_exclusion_df[\"table_name\"] == \"Building Properties\") & (inclusion_exclusion_df[\"exclude_true_false\"] == True)]\n",
    "        \n",
    "        numeric_exclusions = building_exclusions.loc[inclusion_exclusion_df[\"exclusion_type\"] == 'num_range']\n",
    "        \n",
    "        string_exclusions = building_exclusions.loc[inclusion_exclusion_df[\"exclusion_type\"] == 'string_value']\n",
    "        \n",
    "        exclusion_list = [] # <-- This is the list where excluded buildings are stored\n",
    "        \n",
    "        # iterates through the columns in the numeric exclusions included in the inclusion_exclusion dataframe\n",
    "        for exclusion in numeric_exclusions[\"column_name\"]:\n",
    "            \n",
    "            # checks if the exclusion is included in the building_properties dataframe\n",
    "            if exclusion in list(buildings.columns):\n",
    "                \n",
    "                # defines the lower & upper thresholds for the exclusion criteria ( .iloc[0] is used to retrieve the first value from the pd.Series that is returned by .loc )\n",
    "                low_value = numeric_exclusions.loc[numeric_exclusions[\"column_name\"] == exclusion, \"num_range_start\"].iloc[0]\n",
    "                high_value = numeric_exclusions.loc[numeric_exclusions[\"column_name\"] == exclusion, \"num_range_stop\"].iloc[0]\n",
    "                \n",
    "                # Iterates through the buildings in the building_properties dataframe; actual_value is the number for the given building \n",
    "                for building in buildings[\"BuildingId\"]:\n",
    "                    actual_value = buildings.loc[buildings[\"BuildingId\"] == building, exclusion].iloc[0]\n",
    "                    \n",
    "                    # checks if value is within exclusion range\n",
    "                    try:\n",
    "                        if actual_value >= low_value and actual_value <= high_value:\n",
    "                            exclusion_list.append(building)\n",
    "                    except:\n",
    "                        print(f\"Actual value: {type(actual_value)}, high-low: {high_value},{low_value}\")\n",
    "                        \n",
    "        # iterates through the columns in the string_value exclusions included in the inclusion_exclusion dataframe\n",
    "        for exclusion in string_exclusions[\"column_name\"]:\n",
    "            \n",
    "            # checks if the exclusion is included in the building_properties dataframe\n",
    "            if exclusion in list(buildings.columns):\n",
    "                \n",
    "                # This retrieve the comma-separated strings\n",
    "                comma_separated_strings = string_exclusions.loc[string_exclusions[\"column_name\"] == exclusion, \"string_value_criteria\"].iloc[0]\n",
    "                \n",
    "                # This breaks up the string into the individual and strips any spaces from the start/finish\n",
    "                string_list = comma_separated_strings.split(\",\")\n",
    "                string_list = [s.strip() for s in string_list]\n",
    "                \n",
    "                for building in buildings[\"BuildingId\"]:\n",
    "                    actual_value = buildings.loc[buildings[\"BuildingId\"] == building, exclusion].iloc[0]\n",
    "                    \n",
    "                    # checks if the building attribute (actual_value) is in the list of exclusions\n",
    "                    try:\n",
    "                        if actual_value in string_list:\n",
    "                            exclusion_list.append(building)\n",
    "                    except:\n",
    "                        print(f\"Building: {building}, Actual value: {actual_value}, Exclusion list: {string_list}\") # <-- This prints the attributes that caused an error to occur\n",
    "        \n",
    "        \n",
    "        # This defines the list of buildings that are considered 'reducible'\n",
    "        included_buildings = [b for b in buildings[\"BuildingId\"] if b not in exclusion_list]\n",
    "        \n",
    "        \"\"\"\n",
    "        This section finds the combinations of reducible buildings\n",
    "        \"\"\"        \n",
    "        \n",
    "        # This finds all the combinations of reducible schools\n",
    "        combinations_list = []\n",
    "        for i in range(len(included_buildings)):\n",
    "            combo = list(itertools.combinations(included_buildings, i+1))\n",
    "            combinations_list.append(combo)\n",
    "              \n",
    "        # This converts the list into a continuous list of tuples, rather than a list of lists for each iteration\n",
    "        combinations_list = [item for sublist in combinations_list for item in sublist]\n",
    " \n",
    "        # this defines all the combinations within a dictionary using the format (combination tuple) : combination_object\n",
    "        combinations_dict = {}\n",
    "        for combo_tuple in combinations_list:\n",
    "            combinations_dict[combo_tuple] = Combination(combo_tuple, self.FAS_1_excess_core_space, self.buildings_dictionary, self.FAS_1_core_entitlement, self.FAS_1_core_space, self.entitled_core_space)      \n",
    "        \n",
    "        self.combinations = combinations_dict   \n",
    "        \n",
    "        combination_rank = self.find_highest_fas1_core_space(combinations_dict)\n",
    "        \n",
    "        self.reducible_space = combination_rank[1]\n",
    "        \n",
    "        self.reducible_combination = combination_rank[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def find_highest_fas1_core_space(self, dictionary):\n",
    "    \n",
    "        highest_fas1_key = None\n",
    "        highest_fas1_value = float('-inf') #  <-- Sets the core space to negative infitinity to make sure that the first FAS 1 core space value is accepted\n",
    "\n",
    "        for key, combination in dictionary.items():\n",
    "            #print(key, combination)\n",
    "            #print(combination.reducible_space)\n",
    "            if combination.reducible_classification == True: #  <-- tests whether the combination is classed as reducible or not\n",
    "                if combination.reducible_space > highest_fas1_value:\n",
    "                    #print(key, combination)\n",
    "                    highest_fas1_key = key\n",
    "                    highest_fas1_value = combination.reducible_space\n",
    "\n",
    "        return highest_fas1_key, highest_fas1_value\n",
    "    \n",
    "\n",
    "    def enrolment_category(self,enrolment, max_val):\n",
    "        \n",
    "        #  this is used to calcualte the enrolment bands based on the maximum enrolmentvalue in the FAS\n",
    "        bins = np.arange(0, max_val + 25, 25) #  <-- Generates a range of values at intervals of 25;\n",
    "        \n",
    "        if enrolment in bins: \n",
    "            category = enrolment #  <-- deals with enrolments that are equal to any of the enrolment bands, e.g. 50 or 125\n",
    "            \n",
    "        # Uses numpy digitize to categorise the enrollment\n",
    "        else:\n",
    "            category_idx = np.digitize(enrolment, bins)\n",
    "            # Return the highest value in the category\n",
    "            category = bins[category_idx] if category_idx > 0 else None\n",
    "\n",
    "        return category\n",
    "        \n",
    "    \n",
    "    def enrolmentment_categories(self, campus_ID, campus_properties, FAS_1_categories, FAS_2_categories, Sec_FAS, Pri_FAS):\n",
    "        \n",
    "        # this gets the school based on the campus input, which is used to index the school_data dataframe\n",
    "        school = campus_properties.loc[campus_properties['CampusId'] == campus_ID]\n",
    "        \n",
    "        # Converts the campus_id values in the campus properties to string values (should already be done but just a check)        \n",
    "        \n",
    "        primary_FAS_max_enrolments = (len(list(Pri_FAS.columns)) - 2) * 25 # this finds the number of the FAS categories (i.e. maximum number of primary students in the FAS)\n",
    "\n",
    "        secondary_FAS_max_enrolments = (len(list(Sec_FAS.columns)) - 2) * 25 # this finds the number of the FAS categories (i.e. maximum number of secondary students in the FAS)\n",
    "\n",
    "        primary_enrolments = campus_properties.loc[campus_properties['CampusId'] == campus_ID, \"primary_enrolments\"].item() # this retrieves the number of primary enrolments from the school_data for the given campus\n",
    "        \n",
    "        secondary_enrolments = campus_properties.loc[campus_properties['CampusId'] == campus_ID, \"secondary_enrolments\"].item() # this retrieves the number of secondary enrolments from the school_data for the given campus\n",
    "\n",
    "        primary_enrolment_category = self.enrolment_category(primary_enrolments, primary_FAS_max_enrolments) # this finds the enrolment band for the primary FAS\n",
    "\n",
    "        secondary_enrolment_category = self.enrolment_category(secondary_enrolments, secondary_FAS_max_enrolments) # this finds the enrolment band for the secondary FAS\n",
    "\n",
    "        enrolment_categories_tuple = (str(primary_enrolment_category), str(secondary_enrolment_category))\n",
    "        \n",
    "        return enrolment_categories_tuple\n",
    "    \n",
    "    # This returns the entitled space for both primary and secondary FAS 2 categories as two dataframes in a tuple)\n",
    "    def FAS_1_2_entitlement_calc(self, Pri_FAS, Sec_FAS, enrolment_categories):\n",
    "        \n",
    "        primary_enrolments_category = enrolment_categories[0]\n",
    "        \n",
    "        # Removes the enrolment bands from the Pri_FAS df and keeps the core/support classification\n",
    "        Pri_entitled = Pri_FAS['Space classification']\n",
    "        \n",
    "        # Converts the pd.Series into a dataframe\n",
    "        Pri_entitled = Pri_entitled.to_frame(name='Space classification')\n",
    "        \n",
    "        FAS_2_index = list(Pri_entitled.index)\n",
    "        \n",
    "        primary_entitlement_list = []\n",
    "    \n",
    "        # This loop finds the entitled space for each FAS 2 category, and has some (hopefully redundent) code for handling index duplicates and weird stuff\n",
    "        for i in FAS_2_index:\n",
    "            entitlement = Pri_FAS.loc[i, primary_enrolments_category]\n",
    "            if type(entitlement) == pd.Series:\n",
    "                entitlement = entitlement.mean()\n",
    "            primary_entitlement_list.append(entitlement)\n",
    "            \n",
    "        Pri_entitled[\"Entitled Space\"] = primary_entitlement_list\n",
    "        \n",
    "        secondary_enrolments_category = enrolment_categories[1]\n",
    "        \n",
    "        # Removes the enrolment bands from the Pri_FAS df and keeps the core/support classification\n",
    "        Sec_entitled = Sec_FAS['Space classification']\n",
    "        \n",
    "        # Converts the pd.Series into a dataframe\n",
    "        Sec_entitled = Sec_entitled.to_frame(name='Space classification')\n",
    "        \n",
    "        FAS_2_index = list(Sec_entitled.index)\n",
    "        \n",
    "        sec_entitlement_list = []\n",
    "        \n",
    "        for i in FAS_2_index:\n",
    "            entitlement = Sec_FAS.loc[i, secondary_enrolments_category]\n",
    "            if type(entitlement) == pd.Series:\n",
    "                entitlement = entitlement.mean()\n",
    "            sec_entitlement_list.append(entitlement)\n",
    "            \n",
    "        Sec_entitled[\"Entitled Space\"] = sec_entitlement_list\n",
    "\n",
    "        return Pri_entitled, Sec_entitled\n",
    "    \n",
    "    def FAS_2_entitlement_calc(self, pri_entitled, sec_entitled, FAS_2_categories):\n",
    "        \n",
    "        # This retrieves the FAS 2 categories from the FAS_2 categories dataframe\n",
    "        FAS_2_entitlement = FAS_2_categories\n",
    "        \n",
    "        FAS_2_core_entitlement = FAS_2_categories.loc[FAS_2_categories[\"Space classification\"] == \"Core\"]    \n",
    "        \n",
    "        idx = pd.IndexSlice # <--- This is used to deal with the multi-index in the pre/sec entitled dataframes\n",
    "            \n",
    "        entitlement_list = []\n",
    "        \n",
    "        for i in FAS_2_entitlement.index:\n",
    "            entitled_space = 0\n",
    "            if i in pri_entitled.index.get_level_values(1):\n",
    "                entitlement = pri_entitled.loc[idx[:,i], \"Entitled Space\"].sum()\n",
    "                entitled_space += entitlement\n",
    "                \n",
    "            if i in sec_entitled.index.get_level_values(1):\n",
    "                entitlement = sec_entitled.loc[idx[:,i], \"Entitled Space\"].sum()\n",
    "                entitled_space += entitlement\n",
    "            #print(f\"Entitlement: {i}; Area:\", entitled_space) # <-- This can be used to check the result\n",
    "            entitlement_list.append(entitled_space)\n",
    "            \n",
    "        FAS_2_entitlement[\"Entitled Space\"] = entitlement_list\n",
    "        \n",
    "        core_entitlement_list = []\n",
    "        \n",
    "        for i in FAS_2_core_entitlement.index:\n",
    "            entitled_space = 0\n",
    "            if i in pri_entitled.index.get_level_values(1):\n",
    "                entitlement = pri_entitled.loc[idx[:,i],\"Entitled Space\"].sum()\n",
    "                entitled_space += entitlement\n",
    "            if i in sec_entitled.index.get_level_values(1):\n",
    "                entitlement = sec_entitled.loc[idx[:,i],\"Entitled Space\"].sum()\n",
    "                entitled_space += entitlement\n",
    "            #print(f\"Entitlement: {i}; Area:\", entitled_space)  # <-- This can be used to check the result\n",
    "            core_entitlement_list.append(entitled_space)\n",
    "        \n",
    "        FAS_2_core_entitlement[\"Entitled Space\"] = core_entitlement_list\n",
    "        FAS_2_core_entitlement.loc[:, \"Entitled Space\"] = core_entitlement_list\n",
    "        \n",
    "        \n",
    "        # The below section uses the FAS 2 entitlements to aggregate at the FAS 1 level\n",
    "        \n",
    "        self.primary_FAS_1_entitlement = pri_entitled.groupby(level=0)['Entitled Space'].sum()\n",
    "        self.secondary_FAS_1_entitlement = sec_entitled.groupby(level=0)['Entitled Space'].sum()\n",
    "        \n",
    "        self.FAS_1_entitlement = self.primary_FAS_1_entitlement.add(self.secondary_FAS_1_entitlement, fill_value = 0)\n",
    "        \n",
    "        core_pri_entitled = pri_entitled.loc[pri_entitled[\"Space classification\"] == \"Core\"]\n",
    "        core_sec_entitled = sec_entitled.loc[sec_entitled[\"Space classification\"] == \"Core\"]\n",
    "        \n",
    "        self.primary_FAS_1_core_entitlement = core_pri_entitled.groupby(level=0)['Entitled Space'].sum()\n",
    "        self.secondary_FAS_1_core_entitlement = core_sec_entitled.groupby(level=0)['Entitled Space'].sum()\n",
    "        \n",
    "        self.FAS_1_core_entitlement = self.primary_FAS_1_core_entitlement.add(self.secondary_FAS_1_core_entitlement, fill_value = 0)\n",
    "        \n",
    "        return FAS_2_entitlement, FAS_2_core_entitlement\n",
    "\n",
    "# The building class provides the building block for aggregating space for campus objects and combination objects\n",
    "    \n",
    "class Building(Campus):\n",
    "    def __init__(self, building_id, building_properties, FAS_2_space, FAS_2_core_space, aims_extract):\n",
    "        \n",
    "        \"\"\"\n",
    "        Attributes are:\n",
    "        \n",
    "        1. self.FAS_2_space\n",
    "        2. self.FAS_1_space\n",
    "        3. self.FAS_1_core_space\n",
    "        4. self.FAS_1_2_core_space\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.building_id = building_id\n",
    "        self.exclusion_attributes = building_properties[building_properties['BuildingId'] == building_id]\n",
    "        self.FAS_2_space = FAS_2_space.loc[[building_id]]        \n",
    "        self.FAS_1_space = FAS_1_space.loc[[building_id]]\n",
    "        \n",
    "        \n",
    "        # This returns an abbreviated version of the AIMS BRR report which only contains spaces which match the building Id\n",
    "        self.aims_extract = aims_extract[aims_extract['BuildingId'] == building_id].filter(items = ['BuildingId', 'FAS 1', 'FAS 2', 'FloorArea'])\n",
    "        \n",
    "        \n",
    "        # This finds the FAS 2 categories present in the current building\n",
    "        FAS_2_building_categories = self.aims_extract['FAS 2'].unique()\n",
    "        \n",
    "        self.FAS_1_2_data = pd.DataFrame(index = FAS_2_building_categories, columns = ['FAS 1', 'Space Classification', 'Actual Space'])\n",
    "        \n",
    "        # This loop finds the FAS 1 category, floor area and Core/Support category for each FAS 2 category in the building\n",
    "        for FAS_2 in FAS_2_building_categories:\n",
    "            try:\n",
    "                matching_FAS_1 = self.aims_extract.loc[self.aims_extract['FAS 2'] == FAS_2, 'FAS 1'].tolist()\n",
    "                floor_area = self.FAS_2_space.at[building_id, FAS_2]\n",
    "            # This handles buildings which randomly throw up errors (quite rare but seems to happen)\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                matching_category = FAS_2_categories.at[FAS_2, 'Space classification'] # # # !!!!! FAS_2_Categories needs to changed to call on thr PageOne class\n",
    "            except KeyError:\n",
    "                matching_category = 'Support'\n",
    "            \n",
    "            self.FAS_1_2_data.at[FAS_2,'FAS 1'] = matching_FAS_1[0]\n",
    "            self.FAS_1_2_data.at[FAS_2,'Actual Space'] = floor_area\n",
    "            self.FAS_1_2_data.at[FAS_2,'Space Classification'] = matching_category\n",
    "               \n",
    "        self.FAS_1_2_core_space = self.FAS_1_2_data.loc[self.FAS_1_2_data['Space Classification'] == 'Core']\n",
    "        \n",
    "        for i in self.FAS_1_2_core_space['Actual Space']:\n",
    "            if not isinstance(i, float):\n",
    "                print(f\"Value: {i}, type: {type(i)}, building: {building_id}\")\n",
    "        \n",
    "        # This is to handle buildings with no core space (I.e. they have no columns \n",
    "        if len(self.FAS_1_2_core_space) > 0:\n",
    "            self.FAS_1_core_space = self.FAS_1_2_core_space.pivot_table(index = 'FAS 1', values = 'Actual Space', aggfunc = 'sum')\n",
    "        if len(self.FAS_1_2_core_space) < 1:\n",
    "            self.FAS_1_core_space = self.FAS_1_2_core_space.set_index('FAS 1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39f2ed-7f48-455d-b22b-6656e6a6df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11: This creates a campus object for a single campus, and then calculates the reducible space and reducible combination\n",
    "\n",
    "# CampusId can be changed via the first argument in the class:\n",
    "campus = Campus('1883001', campus_properties_df, aims_report_df, FAS_2_space, FAS_1_space, building_properties_df, inclusion_exclusion_df)\n",
    "\n",
    "print(campus.reducible_space)\n",
    "\n",
    "print(campus.reducible_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0476ea0-187a-401b-a1af-99b0a4671b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This demonstrates how to retrieve attribute information from a combination object\n",
    "\n",
    "campus.combinations[('105585', '463586', '105303')].reducible_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eea810-24e2-4c9d-b3b7-8b62b786e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12: This returns the reducible space and classification for a given combination (True = Reducible, False = excluded), as per the campus defined in the above cell.\n",
    "# Copy the desired combination below to view results\n",
    "\n",
    "combination =  ('105585', '463586', '105303')\n",
    "\n",
    "print(campus.combinations[combination].reducible_space, campus.combinations[combination].reducible_classification)\n",
    "\n",
    "campus.combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c770c08-8933-44b5-a916-46a4466d1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13: This calculates the included campuses for the portfolio reducible space calc\n",
    "\n",
    "campus_list = campus_properties_df[\"CampusId\"].unique()\n",
    "\n",
    "campus_exclusions = inclusion_exclusion_df.loc[(inclusion_exclusion_df[\"table_name\"] == \"Campus Properties\") & (inclusion_exclusion_df[\"exclude_true_false\"] == True)]\n",
    "\n",
    "numeric_exclusions = campus_exclusions.loc[inclusion_exclusion_df[\"exclusion_type\"] == 'num_range']\n",
    "\n",
    "string_exclusions = campus_exclusions.loc[inclusion_exclusion_df[\"exclusion_type\"] == 'string_value']\n",
    "\n",
    "exclusion_list = [] # <-- This is the list where excluded campuses are stored\n",
    "\n",
    "# iterates through the columns in the numeric exclusions included in the inclusion_exclusion dataframe\n",
    "for exclusion in numeric_exclusions[\"column_name\"]:\n",
    "\n",
    "    # checks if the exclusion is included in the campus_properties dataframe\n",
    "    if exclusion in list(campus_properties_df.columns):\n",
    "\n",
    "        # defines the lower & upper thresholds for the exclusion criteria ( .iloc[0] is used to retrieve the first value from the pd.Series that is returned by .loc )\n",
    "        low_value = numeric_exclusions.loc[numeric_exclusions[\"column_name\"] == exclusion, \"num_range_start\"].iloc[0]\n",
    "        high_value = numeric_exclusions.loc[numeric_exclusions[\"column_name\"] == exclusion, \"num_range_stop\"].iloc[0]\n",
    "\n",
    "        # Iterates through the campuses in the campus_properties dataframe; actual_value is the number for the given campus\n",
    "        for campus in campus_list:\n",
    "            actual_value = campus_properties_df.loc[campus_properties_df[\"CampusId\"] == campus, exclusion].iloc[0]\n",
    "\n",
    "            # checks if value is within exclusion range\n",
    "            try:\n",
    "                if actual_value >= low_value and actual_value <= high_value:\n",
    "                    exclusion_list.append(campus)\n",
    "            except:\n",
    "                print(f\"Actual value: {type(actual_value)}, high-low: {high_value},{low_value}\")\n",
    "\n",
    "# iterates through the columns in the string_value exclusions included in the inclusion_exclusion dataframe\n",
    "for exclusion in string_exclusions[\"column_name\"]:\n",
    "\n",
    "    # checks if the exclusion is included in the campus_properties dataframe\n",
    "    if exclusion in list(campus_properties_df.columns):\n",
    "\n",
    "        # This retrieve the comma-separated strings\n",
    "        comma_separated_strings = string_exclusions.loc[string_exclusions[\"column_name\"] == exclusion, \"string_value_criteria\"].iloc[0]\n",
    "\n",
    "        # This breaks up the string into the individual and strips any spaces from the start/finish\n",
    "        string_list = comma_separated_strings.split(\",\")\n",
    "        string_list = [s.strip() for s in string_list]\n",
    "\n",
    "        for campus in campus_list:\n",
    "            actual_value = campus_properties_df.loc[campus_properties_df[\"CampusId\"] == campus, exclusion].iloc[0]\n",
    "\n",
    "            # checks if the campus attribute (actual_value) is in the list of exclusions\n",
    "            try:\n",
    "                if actual_value in string_list:\n",
    "                    _exclusion_list.append(campus)\n",
    "            except:\n",
    "                print(f\"Campus: {campus}, Actual value: {actual_value}, Exclusion list: {string_list}\") # <-- This prints the attributes that caused an error to occur\n",
    "                \n",
    "campus_exclusion_list = exclusion_list\n",
    "\n",
    "campus_included_list = [c for c in campus_list if c not in campus_exclusion_list] # <-- This flattens the list so that it's in the correct format\n",
    "\n",
    "print(\"Campus Inclusion List:\", campus_included_list, \"\\n\")\n",
    "\n",
    "print(\"Campus Exclusion List:\", campus_exclusion_list, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801782f6-569a-46b3-8911-4f5bafeab0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14: This cell performs the final portfolio-wide calculation and stores the outputs in a dictionary\n",
    "\n",
    "campus_dictionary = { \"CampusId\" : [],\n",
    "                     \"Campus Object\": [],\n",
    "                     \"Reducible Space\" : [],\n",
    "                     \"Reducible Buildings\" : [] }\n",
    "\n",
    "\n",
    "for campus in campus_included_list:\n",
    "    campus_dictionary[\"CampusId\"].append(campus)\n",
    "    \n",
    "    campus_object = Campus(campus, campus_properties_df, aims_report_df, FAS_2_space, FAS_1_space, building_properties_df, inclusion_exclusion_df)\n",
    "    \n",
    "    campus_dictionary[\"Campus Object\"].append(campus_object)\n",
    "    \n",
    "    if campus_object.percentage_excess_core_space < 1:\n",
    "        \n",
    "        campus_dictionary[\"Reducible Space\"].append(0)\n",
    "        \n",
    "        campus_dictionary[\"Reducible Buildings\"].append(())\n",
    "        \n",
    "    else:\n",
    "        campus_dictionary[\"Reducible Space\"].append(campus_object.reducible_space)\n",
    "        \n",
    "        campus_dictionary[\"Reducible Buildings\"].append(campus_object.reducible_combination)\n",
    "        \n",
    "# Note: Don't worry about the red SettingWithCopyWarning: warnings, they're fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184d5603-2387-487d-8fa2-c8b578220372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15: This provides the final reduducble space figure\n",
    "\n",
    "campus_reducible_space_df = pd.DataFrame(campus_dictionary)\n",
    "\n",
    "portfolio_reducible_space = campus_reducible_space_df[\"Reducible Space\"].sum()\n",
    "\n",
    "portfolio_reducible_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df9ad6-8336-42bc-96fc-764b03237e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16: Save results to CSV\n",
    "\n",
    "# Copy the desired file path here. Make sure it includes the folder and the name of the file. Example: r\"C:\\Users\\justi\\Desktop\\Reducible Space Folder\\Test 123.csv\"\n",
    "download_file_path = r\"__file_path__\\__file_name__.csv \"\n",
    "\n",
    "campus_reducible_space_df.to_CSV(down_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
